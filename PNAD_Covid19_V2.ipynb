{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jsXoFA3UPF3i"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fegastal/PosTech-DataAnalytics_TechChallenge_3/blob/main/PNAD_Covid19_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSRssUPDM-32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cefb2f4-4373-4776-9daf-b274049ed2fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install seaborn\n",
        "!pip install basedosdados"
      ],
      "metadata": {
        "id": "s-_8IsTFMovv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "710e56c9-9e9f-421b-86dd-83e1462e5b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.5.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
            "Requirement already satisfied: basedosdados in /usr/local/lib/python3.10/dist-packages (1.6.11)\n",
            "Requirement already satisfied: Jinja2==3.0.3 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (3.0.3)\n",
            "Requirement already satisfied: ckanapi==4.6 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (4.6)\n",
            "Requirement already satisfied: click==8.0.3 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (8.0.3)\n",
            "Requirement already satisfied: google-cloud-bigquery==2.30.1 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (2.30.1)\n",
            "Requirement already satisfied: google-cloud-bigquery-storage==1.1.0 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (1.1.0)\n",
            "Requirement already satisfied: google-cloud-storage==1.42.3 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (1.42.3)\n",
            "Requirement already satisfied: importlib-metadata<5.0.0,>=4.11.3 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (4.13.0)\n",
            "Requirement already satisfied: loguru<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (0.6.0)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (1.5.3)\n",
            "Requirement already satisfied: pandas-gbq<0.18.0,>=0.17.4 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (0.17.9)\n",
            "Requirement already satisfied: pandavro<2.0.0,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (1.7.2)\n",
            "Requirement already satisfied: pyaml==20.4.0 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (20.4.0)\n",
            "Requirement already satisfied: pyarrow==6.0.0 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (6.0.0)\n",
            "Requirement already satisfied: ruamel.yaml==0.17.10 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (0.17.10)\n",
            "Requirement already satisfied: shapely<2.0.0,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (1.8.5.post1)\n",
            "Requirement already satisfied: toml<0.11.0,>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (0.10.2)\n",
            "Requirement already satisfied: tomlkit==0.7.0 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (0.7.0)\n",
            "Requirement already satisfied: tqdm==4.50.2 in /usr/local/lib/python3.10/dist-packages (from basedosdados) (4.50.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ckanapi==4.6->basedosdados) (67.7.2)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from ckanapi==4.6->basedosdados) (0.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ckanapi==4.6->basedosdados) (2.31.0)\n",
            "Requirement already satisfied: python-slugify>=1.0 in /usr/local/lib/python3.10/dist-packages (from ckanapi==4.6->basedosdados) (8.0.1)\n",
            "Requirement already satisfied: six<2.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from ckanapi==4.6->basedosdados) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.38.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery==2.30.1->basedosdados) (1.59.0)\n",
            "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.29.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery==2.30.1->basedosdados) (1.34.0)\n",
            "Requirement already satisfied: proto-plus>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery==2.30.1->basedosdados) (1.22.3)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery==2.30.1->basedosdados) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery==2.30.1->basedosdados) (2.6.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery==2.30.1->basedosdados) (23.2)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery==2.30.1->basedosdados) (3.20.3)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery==2.30.1->basedosdados) (2.8.2)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage==1.42.3->basedosdados) (2.17.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2==3.0.3->basedosdados) (2.1.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml==20.4.0->basedosdados) (6.0.1)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow==6.0.0->basedosdados) (1.23.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<5.0.0,>=4.11.3->basedosdados) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.3.5->basedosdados) (2023.3.post1)\n",
            "Requirement already satisfied: db-dtypes<2.0.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from pandas-gbq<0.18.0,>=0.17.4->basedosdados) (1.1.1)\n",
            "Requirement already satisfied: pydata-google-auth in /usr/local/lib/python3.10/dist-packages (from pandas-gbq<0.18.0,>=0.17.4->basedosdados) (1.8.2)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from pandas-gbq<0.18.0,>=0.17.4->basedosdados) (1.0.0)\n",
            "Requirement already satisfied: fastavro~=1.5.1 in /usr/local/lib/python3.10/dist-packages (from pandavro<2.0.0,>=1.6.0->basedosdados) (1.5.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery==2.30.1->basedosdados) (1.61.0)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery==2.30.1->basedosdados) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage==1.42.3->basedosdados) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage==1.42.3->basedosdados) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage==1.42.3->basedosdados) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib>=0.0.1->pandas-gbq<0.18.0,>=0.17.4->basedosdados) (1.3.1)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery==2.30.1->basedosdados) (1.5.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify>=1.0->ckanapi==4.6->basedosdados) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ckanapi==4.6->basedosdados) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ckanapi==4.6->basedosdados) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ckanapi==4.6->basedosdados) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ckanapi==4.6->basedosdados) (2023.7.22)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage==1.42.3->basedosdados) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.0.1->pandas-gbq<0.18.0,>=0.17.4->basedosdados) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import basedosdados as bd ## database management system for Bra# zilian public data\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import os\n",
        "from matplotlib import pyplot\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType, StringType\n",
        "from pyspark.sql.functions import col, expr, concat, when, udf\n",
        "\n",
        "spark = SparkSession.builder.appName(\"PNAD_Covic19\").getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "p29aIjVbNSqn",
        "outputId": "502795ac-7167-4bc7-98e2-663a5e1ddea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7814e23848e0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://2bac4a1408f5:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PNAD_Covic19</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dict_basedosdados = bd.read_table(dataset_id='br_ibge_pnad_covid',\n",
        "# table_id='dicionario',\n",
        "# billing_project_id=\"basedosdados-1\")"
      ],
      "metadata": {
        "id": "i4Qd3i39ON6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# base_df = bd.read_table(dataset_id='br_ibge_pnad_covid',\n",
        "#   table_id='microdados',\n",
        "#   billing_project_id=\"basedosdados-1\") \\\n",
        "#           .fillna(0)"
      ],
      "metadata": {
        "id": "1VlqpvpBHXq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# base_df_sql = bd.read_sql(query=\"SELECT  * \\\n",
        "#                                   FROM `basedosdados.br_ibge_pnad_covid.microdados` cov_md \\\n",
        "#                                   WHERE cov_md.mes in (9,10,11)\") \\\n",
        "#                                 .fillna(0)\n"
      ],
      "metadata": {
        "id": "ZRp_3BHzTcEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# base_df_sql"
      ],
      "metadata": {
        "id": "6tG20cdqS-kB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set display options to show all columns and rows\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 30)"
      ],
      "metadata": {
        "id": "LvD6iBPw2wV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# covid_df = spark.createDataFrame(data = base_df_sql)"
      ],
      "metadata": {
        "id": "jKCmpMsVg-uI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Akopaw03G239",
        "outputId": "e8465780-85e6-431b-f221-c191217caa2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('/content/gdrive/MyDrive/colab_notebooks/pnad_covid19.csv',inferSchema = True,header=True)"
      ],
      "metadata": {
        "id": "6TA7Q3YWDLiZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "1539c848-cf75-4d4e-93d7-e3be12138f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-ba831259381b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/colab_notebooks/pnad_covid19.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minferSchema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/content/gdrive/MyDrive/colab_notebooks/pnad_covid19.csv."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df)"
      ],
      "metadata": {
        "id": "P6AADuu7LU1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selecting specific columns from data dictionary"
      ],
      "metadata": {
        "id": "Fq8qJYeBLj5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.select(['UF','Ano','V1013','V1022','A002','A003','B0011','B0012','B0013','B0014','B0015','B0018',\n",
        "                'B0019','B00111','B002','B005','B006','B007','C001','C007D','C007E','C01011','C013','D0051'\n",
        "           ])"
      ],
      "metadata": {
        "id": "L4UgxQNuEXiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "SLP_RbuWFaT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing basedosdados dictionary for the table\n",
        "df_dict = spark.createDataFrame(\n",
        "    bd.read_table(dataset_id='br_ibge_pnad_covid',\n",
        "    table_id='dicionario',\n",
        "    billing_project_id=\"basedosdados-1\").fillna(0)\n",
        ")"
      ],
      "metadata": {
        "id": "lm0X-SjZCwxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dict = df_dict.withColumn('chave',col('chave').cast('int')). \\\n",
        "                            fillna(0)"
      ],
      "metadata": {
        "id": "nz4Z08aeEG21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dict.show()"
      ],
      "metadata": {
        "id": "ux89hEukPHrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dict = df_dict.withColumn(\"chave_coluna\", concat(col(\"nome_coluna\"), col(\"chave\")))"
      ],
      "metadata": {
        "id": "qfscHPe9E7oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dict.show()"
      ],
      "metadata": {
        "id": "kCeikQXZPN3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for column_name in df.columns:\n",
        "#     df = df.withColumnRenamed(column_name, column_name.lower())"
      ],
      "metadata": {
        "id": "HIIuJToWDDer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "for column_name in df.columns:\n",
        "  df = df.withColumn(column_name, col(column_name).cast('int'))"
      ],
      "metadata": {
        "id": "j8oyTGsOMy7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "SIn5t06yc9Z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.fillna(0)\n",
        "df.show()"
      ],
      "metadata": {
        "id": "4oIwIqzUbn_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Altering data and column names"
      ],
      "metadata": {
        "id": "e-csHJRNNJRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "yc5l9m38L8Mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_column_name_dict = {\n",
        "    \"UF\": 'state_code',\n",
        "    'Ano': 'year',\n",
        "    'V1013': 'month',\n",
        "    \"V1022\": \"housing_status\",\n",
        "    \"A002\": \"age\",\n",
        "    \"A003\": \"sex\",\n",
        "    \"B0011\": \"had_fever_last_week\",\n",
        "    \"B0012\": \"had_cough_last_week\",\n",
        "    \"B0013\": \"had_sore_throat_last_week\",\n",
        "    'B0014': \"had_trouble_breathing_last_week\",\n",
        "    \"B0015\": \"had_headache_last_week\",\n",
        "    \"B0018\": \"had_runny_nose_last_week\",\n",
        "    \"B0019\": \"had_lethargy_last_week\",\n",
        "    \"B00111\": \"had_loss_of_smell_last_week\",\n",
        "    \"B002\": \"went_to_healthcare_facility\",\n",
        "    \"B005\": \"was_hospitalized\",\n",
        "    \"B006\": \"used_ventilator\",\n",
        "    \"B007\": \"has_health_insurance\",\n",
        "    \"C001\": \"worked_last_week\",\n",
        "    \"C007D\": \"main_job_activity\",\n",
        "    \"C007E\": \"how_many_employees\",\n",
        "    \"C01011\": \"income_range\",\n",
        "    \"C013\": \"has_worked_remote\",\n",
        "    'D0051': \"coronavirus_related_aid\"\n",
        "}"
      ],
      "metadata": {
        "id": "UptZbKHpNyyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for old_col, new_col in new_column_name_dict.items():\n",
        "    df = df.withColumnRenamed(old_col, new_col)"
      ],
      "metadata": {
        "id": "O8OBn5AxN4iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "cEzt_aEmPqPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symptoms_dict = {\n",
        "    1: \"yes\",\n",
        "    2: \"no\",\n",
        "    3: \"dont_know\",\n",
        "    9: \"ignored\",\n",
        "    0: \"not_applicable\"\n",
        "}"
      ],
      "metadata": {
        "id": "jqx3oVwic_bO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns to translate\n",
        "symptoms_cols = ['had_fever_last_week','had_cough_last_week',\n",
        "                 'had_sore_throat_last_week','had_headache_last_week','had_runny_nose_last_week',\n",
        "                 'had_lethargy_last_week','had_loss_of_smell_last_week','went_to_healthcare_facility','was_hospitalized','has_health_insurance',\n",
        "                 'worked_last_week','has_worked_remote','coronavirus_related_aid','used_ventilator','had_trouble_breathing_last_week']\n",
        "\n",
        "work_cols = ['main_job_activity','how_many_employees','income_range']"
      ],
      "metadata": {
        "id": "hiaFSn-6dSsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brazil_states = {\n",
        "    11: \"RO\",\n",
        "    12: \"AC\",\n",
        "    13: \"AM\",\n",
        "    14: \"RR\",\n",
        "    15: \"PA\",\n",
        "    16: \"AP\",\n",
        "    17: \"TO\",\n",
        "    21: \"MA\",\n",
        "    22: \"PI\",\n",
        "    23: \"CE\",\n",
        "    24: \"RN\",\n",
        "    25: \"PB\",\n",
        "    26: \"PE\",\n",
        "    27: \"AL\",\n",
        "    28: \"SE\",\n",
        "    29: \"BA\",\n",
        "    31: \"MG\",\n",
        "    32: \"ES\",\n",
        "    33: \"RJ\",\n",
        "    35: \"SP\",\n",
        "    41: \"PR\",\n",
        "    42: \"SC\",\n",
        "    43: \"RS\",\n",
        "    50: \"MS\",\n",
        "    51: \"MT\",\n",
        "    52: \"GO\",\n",
        "    53: \"DF\"\n",
        "}"
      ],
      "metadata": {
        "id": "Uy7T1udnNOjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sector_translation = {\n",
        "    1: \"agriculture_livestock_forestry_and_fishing\",\n",
        "    2: \"extraction_of_petroleum_coal_metallic_minerals_stone_sand_salt_etc\",\n",
        "    3: \"manufacturing_industry_including_clothing_and_homemade_manufacturing\",\n",
        "    4: \"supply_of_electricity_and_gas_water_sewerage_and_garbage_collection\",\n",
        "    5: \"construction\",\n",
        "    6: \"wholesale_and_retail_trade\",\n",
        "    7: \"repair_of_motor_vehicles_and_motorcycles\",\n",
        "    8: \"passenger_transport\",\n",
        "    9: \"freight_transport\",\n",
        "    10: \"storage_post_and_delivery_services\",\n",
        "    11: \"accommodation_hotels_inns_etc\",\n",
        "    12: \"food_service_bars_restaurants_food_vendors\",\n",
        "    13: \"information_and_communication_newspapers_radio_and_television_telecommunications_and_it\",\n",
        "    14: \"banks_financial_and_insurance_activities\",\n",
        "    15: \"real_estate_activities\",\n",
        "    16: \"law_firms_engineering_advertising_and_veterinary_services_professional_scientific_and_technical_activities\",\n",
        "    17: \"labor_leasing_security_cleaning_landscaping_and_call_center_activities\",\n",
        "    18: \"public_administration_federal_state_and_municipal_government\",\n",
        "    19: \"education\",\n",
        "    20: \"human_health_and_social_assistance\",\n",
        "    21: \"religious_organizations_unions_and_associations\",\n",
        "    22: \"artistic_sports_and_recreational_activities\",\n",
        "    23: \"hairdressing_beauty_treatment_and_personal_services\",\n",
        "    24: \"paid_domestic_service_to_be_reported_under_occupation\",\n",
        "    25: \"other\",\n",
        "    0: \"not_applicable\"\n",
        "}"
      ],
      "metadata": {
        "id": "GZLuMsz7AKng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employee_translation = {\n",
        "    1: \"1_to_5\",\n",
        "    2: \"6_to_10\",\n",
        "    3: \"11+\",\n",
        "    0: \"not_applicable\"\n",
        "}"
      ],
      "metadata": {
        "id": "gVTseXIADjho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "income_range = {\n",
        "    0: \"0-100\",\n",
        "    1: \"101-300\",\n",
        "    2: \"301-600\",\n",
        "    3: \"601-800\",\n",
        "    4: \"801-1,600\",\n",
        "    5: \"1,601-3,000\",\n",
        "    6: \"3,001-10,000\",\n",
        "    7: \"10,001-50,000\",\n",
        "    8: \"50,001-100,000\",\n",
        "    9: \"100,000+\",\n",
        "    0: \"not_applicable\"\n",
        "}"
      ],
      "metadata": {
        "id": "vv2BOsEIEGl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_and_cast(value):\n",
        "    return symptoms_dict.get(int(value), None)\n",
        "\n",
        "translate_udf = udf(translate_and_cast, StringType())\n",
        "\n",
        "# Apply the UDF to the selected columns\n",
        "for column in symptoms_cols:\n",
        "    df = df.withColumn(column, translate_udf(col(column)))"
      ],
      "metadata": {
        "id": "X5UW_vnfjMox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.schema"
      ],
      "metadata": {
        "id": "YgcaLrirNpJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "bwkh4eInemqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_and_cast_state(value):\n",
        "    return brazil_states.get(value, None)\n",
        "\n",
        "translate_udf = udf(translate_and_cast_state, StringType())\n",
        "\n",
        "# Apply the UDF to the selected columns\n",
        "df = df.withColumn(\"state_code\", col(\"state_code\").cast(IntegerType()))\n",
        "df = df.withColumn('state_code', translate_udf(col('state_code')))"
      ],
      "metadata": {
        "id": "WX2fu84S-l4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "TiqrDDa7_Tnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_and_cast_sector(value):\n",
        "    return sector_translation.get(value, None)\n",
        "\n",
        "translate_udf = udf(translate_and_cast_sector, StringType())\n",
        "\n",
        "# Apply the UDF to the selected columns\n",
        "\n",
        "df = df.withColumn('main_job_activity', translate_udf(col('main_job_activity')))"
      ],
      "metadata": {
        "id": "LbuBrpUOBnab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "SwgElwWlBqLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_and_cast_n_of_employees(value):\n",
        "    return employee_translation.get(value, None)\n",
        "\n",
        "translate_udf = udf(translate_and_cast_sector, StringType())\n",
        "\n",
        "# Apply the UDF to the selected columns\n",
        "\n",
        "df = df.withColumn('how_many_employees', translate_udf(col('how_many_employees')))"
      ],
      "metadata": {
        "id": "x1_7D6fYDsPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "hd0maUJdDzKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_and_cast_income(value):\n",
        "    return income_range.get(value, None)\n",
        "\n",
        "translate_udf = udf(translate_and_cast_income, StringType())\n",
        "\n",
        "# Apply the UDF to the selected columns\n",
        "\n",
        "df = df.withColumn('income_range', translate_udf(col('income_range')))"
      ],
      "metadata": {
        "id": "6Dw_Bp0oEyoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn(\"sex\", F.expr(\"CASE WHEN sex == 1 THEN 'male' ELSE 'female' END\"))\n",
        "df = df.withColumn(\"housing_status\", F.expr(\"CASE WHEN housing_status == 1 THEN 'urban' ELSE 'rural' END\"))"
      ],
      "metadata": {
        "id": "ifsDQy-pJINy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "pGk5WD6PFeWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "id": "Z8k3siOXPl2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating has_covid column based on the symptoms column\n",
        "\n",
        "symptom_col = ['had_fever_last_week','had_cough_last_week',\n",
        "                 'had_sore_throat_last_week','had_headache_last_week','had_runny_nose_last_week',\n",
        "                 'had_lethargy_last_week','had_loss_of_smell_last_week']\n",
        "\n",
        "## if a row has a count of symptoms equal or greater than 2, we identify this research as positive for Covid\n",
        "yes_count = sum(when(col(c) == \"yes\", 1).otherwise(0) for c in symptom_col)"
      ],
      "metadata": {
        "id": "4A4ddD2mMfVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use withColumn to create the has_covid column\n",
        "df = df.withColumn(\"has_covid\", yes_count >= 2)\n"
      ],
      "metadata": {
        "id": "qtwe-IAbOXdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(df.has_covid==True).show()"
      ],
      "metadata": {
        "id": "ZfvSyRX6P5L8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ploting results"
      ],
      "metadata": {
        "id": "FRvo45Q8TI0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "K0nv71ARW7-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pd_state_covid = df.select(['state_code','has_covid','was_hospitalized','has_health_insurance','used_ventilator','went_to_healthcare_facility']).toPandas()"
      ],
      "metadata": {
        "id": "4qMrG9L-b94E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pd_state_covid"
      ],
      "metadata": {
        "id": "ZVdYYIhhTQ-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Covid cases per state"
      ],
      "metadata": {
        "id": "9H6zG5RIb1Xf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "LH0VPtm8f0CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = df_pd_state_covid.query('has_covid==True')\n",
        "filtered_df"
      ],
      "metadata": {
        "id": "GxdVHP0mgt3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting plot size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# creating sns barchart\n",
        "ax = sns.barplot(x=filtered_df['state_code'].value_counts().index,\n",
        "                 y=filtered_df['state_code'].value_counts().values,\n",
        "                 palette='rocket')\n",
        "\n",
        "# Title and label\n",
        "plt.xlabel('State Code')\n",
        "plt.ylabel('Count')\n",
        "plt.title('COVID-19 Cases by State, PNAD Contínua Sep/20 to Nov/20')\n",
        "\n",
        "#adding data label\n",
        "for p in ax.patches:\n",
        "    ax.annotate(format(p.get_height(), '.0f'),\n",
        "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha = 'center', va = 'center',\n",
        "                size=10,\n",
        "                xytext = (0, 9),\n",
        "                textcoords = 'offset points')\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "noGKVW8TfauI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting plot size\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# creating sns barchart\n",
        "ax = sns.countplot(data=filtered_df.query('was_hospitalized == \"yes\" | was_hospitalized==\"no\"'),\n",
        "                 x= 'state_code',\n",
        "                 hue='was_hospitalized',\n",
        "                 palette='rocket')\n",
        "\n",
        "# Title and label\n",
        "plt.xlabel('State Code')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Hospitalized COVID-19 Cases by State, PNAD Contínua Sep/20 to Nov/20')\n",
        "\n",
        "#adding data label\n",
        "for p in ax.patches:\n",
        "    ax.annotate(format(p.get_height(), '.0f'),\n",
        "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha = 'center', va = 'center',\n",
        "                size=10,\n",
        "                xytext = (0, 9),\n",
        "                textcoords = 'offset points')\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show"
      ],
      "metadata": {
        "id": "3jsGIRpzgeEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting plot size\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# creating sns barchart\n",
        "ax = sns.countplot(data=filtered_df.query('was_hospitalized== \"yes\" & (used_ventilator == \"yes\" | used_ventilator==\"no\")'),\n",
        "                 x= 'state_code',\n",
        "                 hue='used_ventilator',\n",
        "                 palette='rocket')\n",
        "\n",
        "# Title and label\n",
        "plt.xlabel('State Code')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Subject used ventilator Cases by State, PNAD Contínua Sep/20 to Nov/20')\n",
        "\n",
        "#adding data label\n",
        "for p in ax.patches:\n",
        "    ax.annotate(format(p.get_height(), '.0f'),\n",
        "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha = 'center', va = 'center',\n",
        "                size=10,\n",
        "                xytext = (0, 9),\n",
        "                textcoords = 'offset points')\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show"
      ],
      "metadata": {
        "id": "HXhXsbIDjk8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# setting plot size\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# creating sns barchart\n",
        "ax = sns.countplot(data=filtered_df.query('went_to_healthcare_facility == \"yes\" & has_health_insurance != \"not_applicable\"'),\n",
        "                 x= 'state_code',\n",
        "                 hue='has_health_insurance',\n",
        "                 orient = 'h',\n",
        "                 palette='rocket')\n",
        "\n",
        "# Title and label\n",
        "plt.xlabel('State Code')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Subject sought healthcare facility, has_health_insurance breakdown, PNAD Contínua Sep/20 to Nov/20')\n",
        "\n",
        "#adding data label\n",
        "for p in ax.patches:\n",
        "    ax.annotate(format(p.get_height(), '.0f'),\n",
        "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha = 'center', va = 'center', rotation = 45,\n",
        "                size=8,\n",
        "                xytext = (0, 9),\n",
        "                textcoords = 'offset points')\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show"
      ],
      "metadata": {
        "id": "H43dwc2fkTwB",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connecting PySpark to BigQuery"
      ],
      "metadata": {
        "id": "jsXoFA3UPF3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "import pandas_gbq"
      ],
      "metadata": {
        "id": "ux4pPGMOR-fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = \"/content/gdrive/MyDrive/colab_notebooks/pnad_covid19_treated.csv\"\n",
        "\n",
        "# Use the write method to save the DataFrame as a CSV file\n",
        "df.write.csv(output_path, header=True, mode=\"overwrite\")"
      ],
      "metadata": {
        "id": "Qay8XtBeP9xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the Cloud Storage bucket for temporary BigQuery export data used\n",
        "# by the connector.\n",
        "bucket = \"pnad_covid19\"\n",
        "spark.conf.set('temporaryGcsBucket', bucket)"
      ],
      "metadata": {
        "id": "IU0nyOlfZSRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.write.format('bigquery') \\\n",
        "#   .option('table', 'pnad_covid29.covid19') \\\n",
        "#   .save()"
      ],
      "metadata": {
        "id": "YCa_XSyGXR_z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}